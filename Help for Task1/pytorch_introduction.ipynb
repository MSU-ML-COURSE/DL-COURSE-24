{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516f1da9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1befce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Введение в Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b8b48",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pytorch и Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870234cc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Основные методы обучения нейронных сетей являются методами оптимизации первого порядка. Они присутствуют, например, в пакете `scipy.optimize`, но либо считают градиенты численно, либо требуют внешних функций, предоставляющих им градиенты в требуемой точке. Написание таких функций вручную для каждой нейронной сети - задача решаемая, но достаточно бессмысленная, т.к. производные, даже аналитически, достаточно легко может считать и машина.\n",
    "\n",
    "Концепция библиотеки pytorch - расширить функционал numpy, добавив туда возможность автоматического расчёта градиентов произвольных функций и их композиций, стараясь максимально сохранить привычную семантику."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791c9559",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Совсем без различий, правда, не обошлось:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee32f781",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`x.reshape((1,2,8))` -> `x.view(1,2,8)`\n",
    "\n",
    "`x.sum(axis=-1)` -> `x.sum(dim=-1)`\n",
    "\n",
    "`x.astype(np.float32)` -> `x.type(torch.float32)` или `x.float()`\n",
    "\n",
    "Более подробный список различий и полезных команд приведён в конце ноутбука."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d20d32",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3.]), tensor([1., 2., 3.]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1., 2., 3.])\n",
    "y = torch.tensor([1., 2., 3.])\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52af92b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Тензоры numpy можно переводить в pytorch без копирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f72221a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.from_numpy(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d49c2b2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Однако, из-за работы с gpu, в pytorch часто предпочитают использовать 32-битные данные, а в numpy типы по умолчанию занимают 64 бита. Аналогичная ситуация и с целочисленными тензорами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff3997ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float64, torch.float32, torch.float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(x).dtype, torch.from_numpy(x.astype(np.float32)).dtype, torch.from_numpy(x).float().dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dbb418",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Также существует обратная операция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97b53c75",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y.numpy()\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Заметим, что теперь все 3 массива x, y, z на самом деле указывают на одну и ту же область памяти:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.,  2.,  3.]),\n",
       " tensor([-1.,  2.,  3.], dtype=torch.float64),\n",
       " array([-1.,  2.,  3.]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0] = -1\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shares_memory(x, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3475773",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40147d8d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "По умолчанию, тензоры, создаваемые в pytorch, не будут требовать, чтобы для них посчитали градиент. Для этого надо добавить дополнительный аргумент `requires_grad=True`, либо вызвав метод `.requires_grad_()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab0ebca3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "y = torch.tensor([1., 2., 3.])\n",
    "y.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e1e20e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Производя операции с переменными, по которым нужно считать градиенты, мы конструируем граф вычислений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64aa2e67",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 3 * x**3 - y**2\n",
    "z.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d4d174",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В каждой переменной есть информация о том, как именно она была получена при проходе вперёд. Исходя из этой информации у тензоров в графе вычислений хранятся функции, которые должны быть вызваны на обратном проходе для расчёта градиента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ac1c637",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SubBackward0 at 0x12ef4d100>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c0262d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Считать для каждого тензора якобиан целиком - сильно неоптимально. Вместо этого на всех промежуточных этапах autograd считает только произведения якобиан-вектор. В частности из-за этого, конечный тензор в графе всегда должен быть скаляром, что выполняется для всех функций потерь по определению.\n",
    "\n",
    "\n",
    "Функции из тензора в скаляр !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba06c0b3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Для примера сделаем из тензора `z` скаляр, сложив все его элементы, и посчитаем градиенты с помощью функции `.backward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "127b2fe1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 9., 36., 81.]), tensor([-2., -4., -6.]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.sum().backward()\n",
    "\n",
    "x.grad, y.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d2f99b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Сравним с посчитанным вручную градиентом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac220b11",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(x.grad, 9 * x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686b4d4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Однако, для оптимизации вычислений, градиенты не вычисляются в явном виде для промежуточных вершин графа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16c2ef65",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/9x_lhtp905l1hz3g_nlhmz1h0000gp/T/ipykernel_4053/676359431.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:483.)\n",
      "  z.grad\n"
     ]
    }
   ],
   "source": [
    "z.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c35eee",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Если такое всё же нужно, требуется указать это явно с помощью вызова `.retain_grad()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73fbbfef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "y = torch.tensor([1., 2., 3.])\n",
    "\n",
    "z = 3 * x**3 - y**2\n",
    "z.retain_grad()\n",
    "\n",
    "z.sum().backward()\n",
    "z.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5991eb15",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Визуализация графа вычислений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5859b399",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Для примера визуализируем, как бы выглядел граф вычислений для линейной регресси.\n",
    "\n",
    "Заметим, что пакет визуализации `pytorchviz` предназначен в первую очередь для визуализации нейронных сетей, поэтому нам необходимо будет использовать класс `torch.nn.Parameter`, который является обёрткой над тензором и несколько расширяет возможности аргумента `requires_grad=True`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Графы визуализируются библиотекой graphviz. Она состоит из системной программы и питоновского пакета.\n",
    "Способы установки бинаря можно найти [тут](https://graphviz.org/download/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4faf2bcc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchviz\n",
      "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /Users/Ilya/Library/Python/3.8/lib/python/site-packages (from torchviz) (1.13.0.dev20220819)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m645.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/Ilya/Library/Python/3.8/lib/python/site-packages (from torch->torchviz) (4.3.0)\n",
      "Building wheels for collected packages: torchviz\n",
      "  Building wheel for torchviz (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4151 sha256=569e1866786a3066630efd74aab6ee39e6af3087dfaae69a03b0b9b7005a0410\n",
      "  Stored in directory: /Users/Ilya/Library/Caches/pip/wheels/05/7d/1b/8306781244e42ede119edbb053bdcda1c1f424ca226165a417\n",
      "Successfully built torchviz\n",
      "Installing collected packages: graphviz, torchviz\n",
      "Successfully installed graphviz-0.20.1 torchviz-0.0.2\n"
     ]
    }
   ],
   "source": [
    "! pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "661eb103",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "948c6484",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.rand(5, 10)\n",
    "y = torch.rand(5)\n",
    "\n",
    "w = nn.Parameter(torch.rand(10))\n",
    "b = nn.Parameter(torch.rand(1))\n",
    "\n",
    "y_hat = X @ w + b\n",
    "\n",
    "loss = torch.mean((y - y_hat)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6acf29a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 5.0.1 (20220820.1526)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"219pt\" height=\"446pt\"\n",
       " viewBox=\"0.00 0.00 219.00 446.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 442)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-442 215,-442 215,4 -4,4\"/>\n",
       "<!-- 5344089488 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>5344089488</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"132.5,-31 78.5,-31 78.5,0 132.5,0 132.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"105.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 5344045760 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5344045760</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"153,-86 58,-86 58,-67 153,-67 153,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"105.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n",
       "</g>\n",
       "<!-- 5344045760&#45;&gt;5344089488 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>5344045760&#45;&gt;5344089488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M105.5,-66.79C105.5,-60.07 105.5,-50.4 105.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109,-41.19 105.5,-31.19 102,-41.19 109,-41.19\"/>\n",
       "</g>\n",
       "<!-- 5344046384 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>5344046384</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"150,-141 61,-141 61,-122 150,-122 150,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"105.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 5344046384&#45;&gt;5344045760 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5344046384&#45;&gt;5344045760</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M105.5,-121.75C105.5,-114.8 105.5,-104.85 105.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109,-96.09 105.5,-86.09 102,-96.09 109,-96.09\"/>\n",
       "</g>\n",
       "<!-- 5344045808 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5344045808</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"150,-196 61,-196 61,-177 150,-177 150,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"105.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 5344045808&#45;&gt;5344046384 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5344045808&#45;&gt;5344046384</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M105.5,-176.75C105.5,-169.8 105.5,-159.85 105.5,-151.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109,-151.09 105.5,-141.09 102,-151.09 109,-151.09\"/>\n",
       "</g>\n",
       "<!-- 5344046528 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5344046528</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"150,-251 61,-251 61,-232 150,-232 150,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"105.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 5344046528&#45;&gt;5344045808 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5344046528&#45;&gt;5344045808</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M105.5,-231.75C105.5,-224.8 105.5,-214.85 105.5,-206.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109,-206.09 105.5,-196.09 102,-206.09 109,-206.09\"/>\n",
       "</g>\n",
       "<!-- 5344046480 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5344046480</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"92,-306 9,-306 9,-287 92,-287 92,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">MvBackward0</text>\n",
       "</g>\n",
       "<!-- 5344046480&#45;&gt;5344046528 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5344046480&#45;&gt;5344046528</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.58,-286.75C67.59,-279.03 79.46,-267.6 89.12,-258.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"91.81,-260.55 96.59,-251.09 86.96,-255.51 91.81,-260.55\"/>\n",
       "</g>\n",
       "<!-- 5344045472 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5344045472</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-366.5 0,-366.5 0,-347.5 101,-347.5 101,-366.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-354.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5344045472&#45;&gt;5344046480 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5344045472&#45;&gt;5344046480</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-347.37C50.5,-339.25 50.5,-326.81 50.5,-316.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-316.17 50.5,-306.17 47,-316.17 54,-316.17\"/>\n",
       "</g>\n",
       "<!-- 5344089328 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>5344089328</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-438 23.5,-438 23.5,-408 77.5,-408 77.5,-438\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-426\" font-family=\"monospace\" font-size=\"10.00\">Weight</text>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-415\" font-family=\"monospace\" font-size=\"10.00\"> (10)</text>\n",
       "</g>\n",
       "<!-- 5344089328&#45;&gt;5344045472 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5344089328&#45;&gt;5344045472</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-407.8C50.5,-398.7 50.5,-386.79 50.5,-376.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-376.84 50.5,-366.84 47,-376.84 54,-376.84\"/>\n",
       "</g>\n",
       "<!-- 5344046432 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>5344046432</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"211,-306 110,-306 110,-287 211,-287 211,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"160.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5344046432&#45;&gt;5344046528 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5344046432&#45;&gt;5344046528</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M151.42,-286.75C143.41,-279.03 131.54,-267.6 121.88,-258.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"124.04,-255.51 114.41,-251.09 119.19,-260.55 124.04,-255.51\"/>\n",
       "</g>\n",
       "<!-- 5344089408 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>5344089408</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"187.5,-372 133.5,-372 133.5,-342 187.5,-342 187.5,-372\"/>\n",
       "<text text-anchor=\"middle\" x=\"160.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\">Bias</text>\n",
       "<text text-anchor=\"middle\" x=\"160.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
       "</g>\n",
       "<!-- 5344089408&#45;&gt;5344046432 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>5344089408&#45;&gt;5344046432</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M160.5,-341.84C160.5,-334.21 160.5,-324.7 160.5,-316.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"164,-316.27 160.5,-306.27 157,-316.27 164,-316.27\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x13e87abb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(loss, params={'Weight': w, 'Bias': b})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199078fe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Что можно сказать об этом графе вычислений?\n",
    "\n",
    "- В листьях графа мы не видим тензора `X`, т.к. нам требуется расчёт градиента только по параметрам модели.\n",
    "\n",
    "- `MvBackward0` соответствует матрично-векторному умножению (отсюда и первые буквы Mv) c матрицей `X`.\n",
    "\n",
    "- `AddBackward0` соответствует добавлению смещения `b`, остальная часть графа - вычисление MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd9bebe",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Аккумулирование градиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bf7fa0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Если не предпринимать никаких дополнительных действий, то множественный вызов `backward()` будет не перезаписывать градиенты тензоров, а складывать их с уже существующим значением (сам граф вычислений каждый раз разрушается). Такое поведение может быть, например, нужно, чтобы посчитать градиент по батчу данных, который не влезает в память компьютера целиком, т.к. градиент модели аддитивен по входным данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4707c58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2453, -1.6462,  0.1616],\n",
       "        [-2.3341,  1.1885, -0.8822],\n",
       "        [-0.1105, -0.8609,  2.1611]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 3, requires_grad=True)\n",
    "y = torch.sum(x * x)\n",
    "y.backward()\n",
    "\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f107c9fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2453,  0.3538,  2.1616],\n",
       "        [-0.3341,  3.1885,  1.1178],\n",
       "        [ 1.8895,  1.1391,  4.1611]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.sum(2 * x)\n",
    "z.backward()\n",
    "\n",
    "x.grad # Заметьте, что ко всем значениям прибавилось 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ea1f28",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Также подобный подход используется в рекуррентных нейронных сетях, где к одному и тому же тензору весов нейросети происходит несколько обращений во время прямого прохода.\n",
    "\n",
    "Чтобы считать градиент с нуля, достаточно удалить тензор. В домашней работе вам покажут способ как делать делать это для всех параметров модели одним вызовом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3533b10e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c050f84c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## In-place операции над тензорами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66e8978",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "По умолчанию, вызов `y = 2 * x` создаст новый тензор, в который скопирует значения x, умноженные на 2. И есть большое желание провести данную операцию на месте, т.е. без аллокации памяти. В nupmy это не имело бы никаких дополнительных последствий, но в pytorch нам надо помнить о графе вычислений, который должен быть без петель, а также может использовать тензоры, рассчитанные при прямом вычислении. В некоторых случаях библиотека может выполнить код и не ругнуться, но описание ситуаций, когда такое сработает, а когда нет, очень сложно, и потому  сами разработчики не рекомендуют использовать in-place операции там, где необходим расчёт градиента."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba68d1f5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In-place операции всегда имеют символ `_` на конце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e82ed0f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [3, 3]], which is output 0 of ExpBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m z \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# replace this with c = b + 2 and the autograd error will go away\u001b[39;00m\n\u001b[1;32m      4\u001b[0m y\u001b[38;5;241m.\u001b[39mexp_()  \u001b[38;5;66;03m# inplace operation!\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/_tensor.py:484\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    476\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    477\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    482\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    483\u001b[0m     )\n\u001b[0;32m--> 484\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/autograd/__init__.py:191\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [3, 3]], which is output 0 of ExpBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 3, requires_grad=True)\n",
    "y = 2 * x\n",
    "z = y ** 2  # replace this with c = b + 2 and the autograd error will go away\n",
    "y.exp_()  # inplace operation!\n",
    "z.sum().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd83d9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Другой распространённый в numpy сценарий - маскированное изменение значений тензора. Это тоже является in-place операцией. В pytorch для этого лучше использовать функцию `torch.where`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67941a26",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6676, 0.1258, 0.2730],\n",
       "        [0.3598, 0.8222, 0.4697],\n",
       "        [0.4799, 0.5896, 0.5743]], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3,3, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c8789cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad is being used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a leaf Variable that requires grad is being used in an in-place operation."
     ]
    }
   ],
   "source": [
    "x[x > 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b38cb24f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1258, 0.2730],\n",
       "        [0.3598, 0.0000, 0.4697],\n",
       "        [0.4799, 0.0000, 0.0000]], grad_fn=<WhereBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(x > 0.5, 0, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598ddf7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##  Копирование тензоров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd6c62f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В numpy существует интуитивно понятная функция `copy()`, но в pytorch функции с таким названием нет! Это связано с тем, что тензоры в pytorch привязаны к графу вычислений, который надо также учитывать при копировании."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d42cec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`.clone()` копирует тензор и сохраняет его привязку к текущему дереву вычислений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b5a5640",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, requires_grad=True)\n",
    "y = x.clone()\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a0ca15",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`.detach()` исходя из своего названия, копирует лишь значения элементов тензора, \n",
    "отвязывая его от текущего графа вычислений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "911e8fec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.detach()\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Продемонстрируем на графе вычислений эти две операции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 5.0.1 (20220820.1526)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"149pt\" height=\"380pt\"\n",
       " viewBox=\"0.00 0.00 149.00 380.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 376)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-376 145,-376 145,4 -4,4\"/>\n",
       "<!-- 5546170544 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>5546170544</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"74.5,-31 20.5,-31 20.5,0 74.5,0 74.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"47.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n",
       "</g>\n",
       "<!-- 5546045056 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5546045056</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"92,-86 3,-86 3,-67 92,-67 92,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"47.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 5546045056&#45;&gt;5546170544 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5546045056&#45;&gt;5546170544</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.5,-66.79C47.5,-60.07 47.5,-50.4 47.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"51,-41.19 47.5,-31.19 44,-41.19 51,-41.19\"/>\n",
       "</g>\n",
       "<!-- 5545306528 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>5545306528</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"92,-141 3,-141 3,-122 92,-122 92,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"47.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 5545306528&#45;&gt;5546045056 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5545306528&#45;&gt;5546045056</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.5,-121.75C47.5,-114.8 47.5,-104.85 47.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"51,-96.09 47.5,-86.09 44,-96.09 51,-96.09\"/>\n",
       "</g>\n",
       "<!-- 5082764960 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5082764960</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-306 0,-306 0,-287 101,-287 101,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5082764960&#45;&gt;5545306528 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5082764960&#45;&gt;5545306528</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M45.18,-286.68C40.27,-277.97 33.31,-264.09 30.5,-251 27.54,-237.2 29.39,-199.65 33.5,-177 35.09,-168.23 37.9,-158.79 40.59,-150.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"43.97,-151.8 44.05,-141.2 37.38,-149.43 43.97,-151.8\"/>\n",
       "</g>\n",
       "<!-- 5082924800 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5082924800</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"141,-251 40,-251 40,-232 141,-232 141,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"90.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">CloneBackward0</text>\n",
       "</g>\n",
       "<!-- 5082764960&#45;&gt;5082924800 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5082764960&#45;&gt;5082924800</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.11,-286.75C62.76,-279.26 71.04,-268.28 77.95,-259.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"80.79,-261.18 84.02,-251.09 75.2,-256.96 80.79,-261.18\"/>\n",
       "</g>\n",
       "<!-- 5546168544 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5546168544</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-372 23.5,-372 23.5,-342 77.5,-342 77.5,-372\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\">X</text>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n",
       "</g>\n",
       "<!-- 5546168544&#45;&gt;5082764960 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5546168544&#45;&gt;5082764960</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-341.84C50.5,-334.21 50.5,-324.7 50.5,-316.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-316.27 50.5,-306.27 47,-316.27 54,-316.27\"/>\n",
       "</g>\n",
       "<!-- 5082816720 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5082816720</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"132,-196 43,-196 43,-177 132,-177 132,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">ExpBackward0</text>\n",
       "</g>\n",
       "<!-- 5082816720&#45;&gt;5545306528 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5082816720&#45;&gt;5545306528</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M80.89,-176.75C75.24,-169.26 66.96,-158.28 60.05,-149.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"62.8,-146.96 53.98,-141.09 57.21,-151.18 62.8,-146.96\"/>\n",
       "</g>\n",
       "<!-- 5082924800&#45;&gt;5082816720 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5082924800&#45;&gt;5082816720</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90,-231.75C89.61,-224.8 89.05,-214.85 88.55,-206.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"92.05,-205.88 87.99,-196.09 85.06,-206.27 92.05,-205.88\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x12e9cf910>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nn.Parameter(torch.rand(3))\n",
    "y = nn.Parameter(torch.rand(3))\n",
    "\n",
    "x1 = x.clone().exp_() # здесь мы in-place поменяли клон тензора х\n",
    "z = x + x1 + y.detach()\n",
    "\n",
    "make_dot(z, params={'X': x, 'Y': y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Что можно понять из данного графа?\n",
    "\n",
    "- Видна операция `CloneBackward0`, которая клонирует тензор `x`. Благодаря ей в сумме участвует как исходный тензор, так и его экспонированная версия.\n",
    "\n",
    "- Во второй сумме мы не видим параметра `y`, потому что он входит в граф вычислений только через `.detach()`, что убирает проход градиентов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e8c01f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Менеджеры контекста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3d7d6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Поведением градиента сразу группы тензоров можно управлять с помощью специальных функций, которые вызываются через стандартную семантику питона `with foo():`, где foo - одна из трёх функций ниже:\n",
    "\n",
    "- Default Mode\n",
    "\n",
    "    Стандартный режим работы pytorch, в котором управление градиентами происходит через `requires_grad`. Явно его нужно вызывать только внутри других контекстных менеджеров, чтобы временно снова активировать расчёт градиентов (что случается крайне редко) вызовом `torch.enable_grad()`.\n",
    "\n",
    "\n",
    "- No grad mode\n",
    "\n",
    "    Данный режим используется когда блока кода нет необходимости вычислять градиенты, что занимает как вычислительные ресурсы, так и дополнительную память. Реализуется вызовом `torch.no_grad()`.\n",
    "\n",
    "\n",
    "- Inference mode\n",
    "\n",
    "    Аналогично No grad mode отключает расчёт градиентов, но кроме того проводит дополнительные оптимизации, что делает вычисления внутри блока кода ещё быстрее. Однако, тензоры, созданные в таком блоке будет невозможно использовать совместно с тензорами, для которых расчёт градиента необходим. Реализуется вызовом `torch.inference_mode()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "653829e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, requires_grad=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x + x\n",
    "    \n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0e5d934",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def foo(x):\n",
    "    return x + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4cf8449",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = foo(x)\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f9aed7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Работа с GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57efa9ff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "pytorch из коробки умеет делать вычисления на gpu через множество различных бекэндов, самый распространённый из которых -  cuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9852805e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "# GPU на Mac также поддерживаются через backend mps\n",
    "x = torch.tensor([1.,2.,3.], requires_grad=True, device=device)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da70f5f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Тензоры можно передавать с устройства на устройство с помощью вызова `.to(device)` или `.cpu()`/`.cuda()`. Последним пользоваться не рекомендуется, т.к. на устройстве может не быть cuda. \n",
    "\n",
    "Конвертация в numpy работает ТОЛЬКО для тензоров, находящихся на cpu и без градиентов!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ebf90e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "x.numpy() # не перевели на cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4519b78",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "x.cpu().numpy() # не убрали градиент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0db9c428",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.detach().cpu().numpy() # вот теперь хорошо"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44977b5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Нельзя использовать в одной операции тензоры, находящиеся на разных устройствах. По умолчанию тензоры создаются на cpu. Однако, часто встречаются ситуации, когда необходимо добавить в граф вычислений созданные на месте тензоры. Если явно не указать устройство для этих тензоров, то случится ошибка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4a80ae5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "y = torch.rand(3)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc8032a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6965, 2.6396, 3.7496], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(3, device=x.device)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98386c1",
   "metadata": {},
   "source": [
    "## `.item`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91214896",
   "metadata": {},
   "source": [
    "Часто при подсчёте метрик возникают тензоры из одного элемента/скаляры, которые могут находится на GPU или быть частью графа вычислений.\n",
    "\n",
    "Сохранение таких тензоров в массив приведёт к утечке памяти. Чтобы этого избежать существует возможность трансформирования таких тензоров в Python скаляр:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfabbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, requires_grad=True)\n",
    "loss = torch.mean(x, dim=0, keepdim=True)\n",
    "loss, loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb7306a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Дополнительные библиотеки и функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "При прохождении данного курса вам могут оказаться полезны следующие функции:\n",
    "\n",
    "- Сконкатенировать набор тензоров вдоль заданной размерности [torch.cat](https://pytorch.org/docs/stable/generated/torch.cat.html)\n",
    "\n",
    "- Соединить тензоры одинаковой формы вдоль новой размерности [torch.stack]()\n",
    "- Добавить/убрать новую \"единичную\" размерность в тензор [torch.unsqueeze](https://pytorch.org/docs/stable/generated/torch.squeeze.html)/[torch.squeeze](https://pytorch.org/docs/stable/generated/torch.squeeze.html)\n",
    "- Разбить тензор на заданное число блоков [torch.chunk](https://pytorch.org/docs/stable/generated/torch.chunk.html)\n",
    "- Переставить между собой __две__ размерности [torch.transpose](https://pytorch.org/docs/stable/generated/torch.transpose.html)\n",
    "- Переставить местами __все__ размерности [torch.permute](https://pytorch.org/docs/stable/generated/torch.permute.html)\n",
    "- Повторить тензор [torch.tile](https://pytorch.org/docs/stable/generated/torch.tile.html)/[torch.repeat](https://pytorch.org/docs/stable/generated/torch.Tensor.repeat.html)\n",
    "- Найти максимальный элемент (возвращает И положение, И значение)[torch.max](https://pytorch.org/docs/stable/generated/torch.max.html)\n",
    "- Поэлементный максимум между __двумя__ тензорами[torch.maximum](https://pytorch.org/docs/stable/generated/torch.maximum.html)\n",
    "- \"Выпрямить\" тензор, объединив все размерности в одну [torch.ravel](https://pytorch.org/docs/stable/generated/torch.ravel.html)\n",
    "- Объединить только заданные размерности [torch.flatten](https://pytorch.org/docs/stable/generated/torch.flatten.html)\n",
    "- Вернуть k наибольших элементов [torch.topk](https://pytorch.org/docs/stable/generated/torch.topk.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Кроме того, Pytorch включает в себя набор дополнительных модулей, которые аналогичны соответствующим модулям в numpy с той лишь разницей, что здесь через все функции можно автоматически посчитать градиент.\n",
    "\n",
    "- [torch.linalg](https://pytorch.org/docs/stable/linalg.html) матричные операции, разложения и СЛАУ\n",
    "\n",
    "- [torch.special](https://pytorch.org/docs/stable/special.html) функция ошибок и другие специальные функции, доступна с версии 1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba710237",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
